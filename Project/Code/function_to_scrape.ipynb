{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "643fded9-8c3d-4fb0-ab3b-b5a0c637db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db6f6a4e-0dd1-42e4-a37e-b2c60a43098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    connection = pymysql.connect(host=\"localhost\", user=\"root\", passwd=\"\", database=\"myapp\")\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e57bb8a1-f69d-4df9-9a60-7967b5bbe271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_teachers(connection):\n",
    "    cursor = connection.cursor()\n",
    "    retrive = \"SELECT users.id, users.fname_en, users.lname_en, users.fname_th, users.lname_th FROM users\"\n",
    "    cursor.execute(retrive)\n",
    "    teachers = cursor.fetchall()\n",
    "    return [f\"{t[1]} {t[2]} ({t[3]} {t[4]})\" for t in teachers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ff8208-eebb-40e6-86df-83e114cab28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_webdriver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    service = Service(r'D:/web scraping/chromedriver.exe')\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86609e2b-ed40-4f97-bddb-48a110fec862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tci_data(teacher_names):\n",
    "    driver = setup_webdriver()\n",
    "    results = []\n",
    "    \n",
    "    for teacher in teacher_names:\n",
    "        driver.get('https://search.tci-thailand.org/advance_search.html')\n",
    "        select = Select(driver.find_element(By.NAME, \"criteria[]\"))\n",
    "        select.select_by_value('author')\n",
    "        \n",
    "        search_box = driver.find_element(By.NAME, 'keyword[]')\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(teacher)\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(5)\n",
    "\n",
    "        select = Select(driver.find_element(By.ID, \"limit_num_page\"))\n",
    "        select.select_by_value('100')\n",
    "        time.sleep(5)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        main_container = soup.find('div', {'class': 'filter_panel card col-md-9'})\n",
    "        if not main_container:\n",
    "            continue\n",
    "\n",
    "        content_section = main_container.find('div', {'class': 'content'})\n",
    "        if not content_section:\n",
    "            continue\n",
    "\n",
    "        for paper in content_section.find_all('div', class_='content'):\n",
    "            paper_title = paper.find(\"p\").text.strip()\n",
    "            author_section = paper.find(\"p\", class_=\"authors\")\n",
    "            journal_section = paper.find_all(\"p\")[-1]\n",
    "            document_type_section = paper.find(\"option\", {\"value\": \"journal_title\"})\n",
    "            citation_section = paper.find(\"p\", style=re.compile(r\"float:right;\"))\n",
    "            \n",
    "            journal_link = journal_section.find(\"a\")\n",
    "            journal_name = journal_link.text.strip() if journal_link else \"\"\n",
    "            \n",
    "            year_match = re.search(r'\\b(19|20)\\d{2}\\b', journal_section.text)\n",
    "            publication_year = year_match.group(0) if year_match else \"\"\n",
    "            \n",
    "            page_match = re.search(r'pp\\.\\s*(\\d+-\\d+)', journal_section.text)\n",
    "            page_numbers = page_match.group(1) if page_match else \"\"\n",
    "            \n",
    "            authors = \", \".join(a.text for a in author_section.find_all(\"a\")) if author_section else \"\"\n",
    "            document_type = document_type_section.text if document_type_section else \"Journal\"\n",
    "            \n",
    "            citation_count_text = citation_section.find(\"a\").text.strip() if citation_section else \"\"\n",
    "            citation_count = re.search(r'cited (\\d+)', citation_count_text)\n",
    "            citation_count = citation_count.group(1) if citation_count else \"\"\n",
    "            \n",
    "            title_section = paper.find(\"p\", style=re.compile(r\"margin-left:0;float:left; width:85%;\"))\n",
    "            title_link = title_section.find(\"a\") if title_section else None\n",
    "            article_link = title_link[\"href\"] if title_link else \"\"\n",
    "            \n",
    "            url = f\"https://search.tci-thailand.org/{article_link}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(5)\n",
    "            \n",
    "            soup_doi = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            doi_section = soup_doi.find(\"span\", {\"id\": \"doi_english\"})\n",
    "            doi_link = doi_section.find(\"a\") if doi_section else None  \n",
    "            doi_url = doi_link[\"href\"] if doi_link else \"\"\n",
    "            \n",
    "            doi_match = re.search(r\"10\\.\\d{4,9}/[\\w\\-.]+\", doi_url)\n",
    "            doi_number = doi_match.group(0) if doi_match else \"\"\n",
    "\n",
    "            results.append({\n",
    "                \"Year\": publication_year,\n",
    "                \"Title\": paper_title,\n",
    "                \"Authors\": authors,\n",
    "                \"Document Type\": document_type,\n",
    "                \"Journals/Transactions\": journal_name,\n",
    "                \"Pages\": page_numbers,\n",
    "                \"Citations\": citation_count,\n",
    "                \"DOI\": doi_number\n",
    "            })\n",
    "    \n",
    "    driver.quit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e80bb2-926e-4ff9-8e11-484b5e4d2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_teacher_data(teacher_name):\n",
    "    return scrape_tci_data([teacher_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ff9b6a8-0113-40f8-8901-7632fda8df2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Year': '2016', 'Title': 'Extended Hierarchical Extreme Learning Machine with Multilayer Perceptron', 'Authors': 'Khanittha Phumrattanaprapin, Punyaphol Horata', 'Document Type': 'Journal', 'Journals/Transactions': 'ECTI Transactions on Computer and Information Technology', 'Pages': '196-204', 'Citations': '0', 'DOI': ''}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    connection = connect_to_db()\n",
    "    teacher_names = ['Punyaphol Horata']\n",
    "    connection.close()\n",
    "    scraped_data = scrape_tci_data(teacher_names)\n",
    "    for data in scraped_data:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e247fd-48c1-47ac-83d5-b06508a12e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
